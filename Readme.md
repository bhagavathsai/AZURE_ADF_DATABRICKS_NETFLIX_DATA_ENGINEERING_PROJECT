Netflix Data Engineering Project

ğŸš€ Project Overview

This project demonstrates an end-to-end data engineering pipeline using Azure Data Factory (ADF), Azure Data Lake Storage Gen2 (ADLS), and Databricks (Delta Live Tables). The dataset used is Netflix content metadata sourced from a public GitHub repository. The pipeline is built in three layers: Bronze, Silver, and Gold, following the Medallion architecture.

ğŸ§± Architecture & Tools

Azure Data Factory (ADF): Data ingestion and validation from GitHub

Azure Data Lake Storage Gen2 (ADLS): Centralized storage for all layers

Databricks: Auto Loader, Delta Live Tables (DLT), workflows, and transformations

Delta Lake: Format for scalable and ACID-compliant tables

ğŸªª Data Sources

Dataset: Netflix Titles on GitHub

Files: netflix_cast.csv, netflix_directors.csv, netflix_countries.csv, netflix_categories.csv, netflix_titles.csv

ğŸ› ï¸ Step-by-Step Implementation

ğŸ”¸ 1. Data Ingestion Using ADF

Used ADF pipelines to validate if files exist in GitHub.

Iterated over files using ForEach activity.

Copied files into ADLS Bronze layer:

/bronze/netflix_cast/

/bronze/netflix_directors/

/bronze/netflix_countries/

/bronze/netflix_categories/

Skipped netflix_titles.csv in ADF to demonstrate Databricks Auto Loader.

ğŸ”¸ 2. Bronze to Silver Using Databricks Workflows

Created separate workflows for each entity.

Used widgets to pass folder name as parameter.

Read data from Bronze, transformed/validated it, and wrote to Silver layer:

/silver/netflix_cast/

/silver/netflix_directors/

/silver/netflix_countries/

/silver/netflix_categories/

ğŸ”¸ 3. Databricks Auto Loader for Netflix Titles

Used Auto Loader to ingest netflix_titles.csv directly to Bronze.

Workflow to run this only on Sundays using dbutils.widgets.get("weekday") logic.

ğŸ§ª Gold Layer with Delta Live Tables (DLT)

âœ… Quality Rules

looktables_rules = {
    "rule1": "show_id is NOT NULL"
}

ğŸ“ Gold Tables from Silver Layer (Lookup Tables)

@dlt.table(name='gold_netflix_directors')
@dlt.expect_all(looktables_rules)
...

@dlt.table(name='gold_netflix_countries')
@dlt.expect_all(looktables_rules)
...

@dlt.table(name='gold_netflix_category')
@dlt.expect_all(looktables_rules)
...

@dlt.table(name='gold_netflix_cast')
@dlt.expect_or_drop("rule1", "show_id IS NOT NULL")
...

ğŸ“„ Gold Table for netflix_titles

@dlt.table
def gold_stg_netflixtitles():
    df = spark.readStream.format('delta').load("abfss://silver@.../netflix_titles")
    return df

@dlt.view
def gold_trns_netflixtitles():
    df = spark.readStream.table("LIVE.gold_stg_netflixtitles")
    return df.withColumn("newflag", lit(1))

@dlt.table
@dlt.expect_all_or_drop({"rule1": "newflag IS NOT NULL", "rule2": "show_id IS NOT NULL"})
def gold_netflix_titles():
    df = spark.readStream.table("LIVE.gold_trns_netflixtitles")
    return df

ğŸ§¾ Folder Structure

netflix-data-engineering/
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ code_notebook/
â”‚   â””â”€â”€ netflix_project.dbc
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ netflix_cast.csv
â”‚   â”œâ”€â”€ netflix_category.csv
â”‚   â”œâ”€â”€ netflix_countries.csv
â”‚   â”œâ”€â”€ netflix_directors.csv
â”‚   â””â”€â”€ netflix_titles.csv
â”œâ”€â”€ Images/
â”‚   â”œâ”€â”€ adf_workflow_to_bronze.jpeg
â”‚   â”œâ”€â”€ bronze_to_silver_for4files.jpeg
â”‚   â”œâ”€â”€ datalake_container.jpeg
â”‚   â”œâ”€â”€ dlt_gold_layer.jpeg
â”‚   â”œâ”€â”€ Project_Architecture.jpeg
â”‚   â””â”€â”€ workflow_of_netflix_titles.jpeg
â”œâ”€â”€ README.md


âœ… Features Implemented



ğŸ“ˆ Future Improvements

Add Power BI or Tableau dashboard on Gold layer

Implement Slowly Changing Dimension (SCD) logic for titles

Add column-level data quality checks (null %, data type expectations)

ğŸ“¬ Contact

For questions or collaboration, reach out at [your-email@example.com]

Built with ğŸ’» Databricks, ADF, and Delta Lake